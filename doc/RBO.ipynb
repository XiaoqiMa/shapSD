{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:48:09.691093Z",
     "start_time": "2019-12-09T22:48:09.446557Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class RankingSimilarity(object):\n",
    "    \"\"\"\n",
    "    This class will include some similarity measures between two different\n",
    "    ranked lists.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, S, T, verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize the object with the required lists.\n",
    "        Examples of lists:\n",
    "        S = ['a', 'b', 'c', 'd', 'e']\n",
    "        T = ['b', 'a', 1, 'd']\n",
    "        Both lists relfect the ranking of the items of interest, for example,\n",
    "        list S tells us that item 'a' is ranked first, 'b' is ranked second, etc.\n",
    "        Args:\n",
    "            S, T (list or numpy array): lists with alphanumeric elements. They\n",
    "                could be of different lengths. Both of the them should be\n",
    "                ranked, i.e., each element's position reflects its respective\n",
    "                ranking in the list. Also we will require that there is no\n",
    "                duplicate element in each list.\n",
    "        \"\"\"\n",
    "\n",
    "        assert(type(S) in [list, np.ndarray])\n",
    "        assert(type(T) in [list, np.ndarray])\n",
    "\n",
    "        assert(len(S) == len(set(S)))\n",
    "        assert(len(T) == len(set(T)))\n",
    "\n",
    "        self.S, self.T = S, T\n",
    "        self.N_S, self.N_T = len(S), len(T)\n",
    "        self.verbose = verbose\n",
    "        self.p = 0.5  # just a place holder\n",
    "\n",
    "    def _bound_range(self, value):\n",
    "        \"\"\"Bounds the value to [0.0, 1.0].\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            assert(0 <= value <= 1 or np.isclose(1, value))\n",
    "            return value\n",
    "\n",
    "        except AssertionError:\n",
    "            print('Value out of [0, 1] bound, will bound it.')\n",
    "            larger_than_zero = max(0.0, value)\n",
    "            less_than_one = min(1.0, larger_than_zero)\n",
    "            return less_than_one\n",
    "\n",
    "    def rbo(self, k=None, p=1.0, ext=False):\n",
    "        \"\"\"\n",
    "        This the weighted non-conjoint measures, namely, rank-biased overlap.\n",
    "        Unlike Kendall tau which is correlation based, this is intersection\n",
    "        based.\n",
    "        The implementation if from Eq. (4) or Eq. (7) (for p != 1) from the RBO\n",
    "        paper: http://www.williamwebber.com/research/papers/wmz10_tois.pdf\n",
    "        If p=1, it returns to the un-bounded set-intersection overlap, according\n",
    "        to Fagin et al.\n",
    "        https://researcher.watson.ibm.com/researcher/files/us-fagin/topk.pdf\n",
    "        The fig. 5 in that RBO paper can be used as test case.\n",
    "        Note there the choice of p is of great importance, since it essentically\n",
    "        control the 'top-weightness'. Simply put, to an extreme, a small p value\n",
    "        will only consider first few items, whereas a larger p value will\n",
    "        consider more itmes. See Eq. (21) for quantitative measure.\n",
    "        Args:\n",
    "            k (int), default None: The depth of evaluation.\n",
    "            p (float), default 1.0: Weight of each agreement at depth d:\n",
    "                p**(d-1). When set to 1.0, there is no weight, the rbo returns\n",
    "                to average overlap.\n",
    "            ext (Boolean) default False: If True, we will extropulate the rbo,\n",
    "                as in Eq. (23)\n",
    "        Returns:\n",
    "            The rbo at depth k (or extrapolated beyond)\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.N_S and not self.N_T:\n",
    "            return 1  # both lists are empty\n",
    "\n",
    "        if not self.N_S or not self.N_T:\n",
    "            return 0  # one list empty, one non-empty\n",
    "\n",
    "        if k is None:\n",
    "            k = float('inf')\n",
    "        k = min(self.N_S, self.N_T, k)\n",
    "\n",
    "        # initilize the agreement and average overlap arrays\n",
    "        A, AO = [0] * k, [0] * k\n",
    "        if p == 1.0:\n",
    "            weights = [1.0 for _ in range(k)]\n",
    "        else:\n",
    "            assert(0.0 < p < 1.0)\n",
    "            weights = [1.0 * (1 - p) * p**d for d in range(k)]\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "        # using dict for O(1) look up\n",
    "        S_running, T_running = {self.S[0]: True}, {self.T[0]: True}\n",
    "        A[0] = 1 if self.S[0] == self.T[0] else 0\n",
    "        AO[0] = weights[0] if self.S[0] == self.T[0] else 0\n",
    "\n",
    "        PP = ProgressPrintOut(k) if self.verbose else NoPrintOut()\n",
    "        for d in range(1, k):\n",
    "\n",
    "            PP.printout(d, delta=1)\n",
    "            tmp = 0\n",
    "            # if the new item from S is in T already\n",
    "            if self.S[d] in T_running:\n",
    "                tmp += 1\n",
    "            # if the new item from T is in S already\n",
    "            if self.T[d] in S_running:\n",
    "                tmp += 1\n",
    "            # if the new items are the same, which also means the previous\n",
    "            # two cases didn't happen\n",
    "            if self.S[d] == self.T[d]:\n",
    "                tmp += 1\n",
    "\n",
    "            # update the agreement array\n",
    "            A[d] = 1.0 * ((A[d - 1] * d) + tmp) / (d + 1)\n",
    "\n",
    "            # update the average overlap array\n",
    "            if p == 1.0:\n",
    "                AO[d] = ((AO[d - 1] * d) + A[d]) / (d + 1)\n",
    "            else:  # weighted average\n",
    "                AO[d] = AO[d - 1] + weights[d] * A[d]\n",
    "\n",
    "            # add the new item to the running set (dict)\n",
    "            S_running[self.S[d]] = True\n",
    "            T_running[self.T[d]] = True\n",
    "\n",
    "        if ext and p < 1:\n",
    "            return self._bound_range(AO[-1] + A[-1] * p**k)\n",
    "        else:\n",
    "            return self._bound_range(AO[-1])\n",
    "\n",
    "    def rbo_ext(self, p=0.98):\n",
    "        \"\"\"\n",
    "        This is the ultimate implementation of the rbo, namely, the extrapolated\n",
    "        version. The corresponding formula is Eq. (32) in the rbo paper\n",
    "        \"\"\"\n",
    "\n",
    "        assert(0.0 < p < 1.0)\n",
    "        self.p = p\n",
    "\n",
    "        if not self.N_S and not self.N_T:\n",
    "            return 1  # both lists are empty\n",
    "\n",
    "        if not self.N_S or not self.N_T:\n",
    "            return 0  # one list empty, one non-empty\n",
    "\n",
    "        # since we are dealing with un-even lists, we need to figure out the\n",
    "        # long (L) and short (S) list first. The name S might be confusing\n",
    "        # but in this function, S refers to short list, L refers to long list\n",
    "        if len(self.S) > len(self.T):\n",
    "            L, S = self.S, self.T\n",
    "        else:\n",
    "            S, L = self.S, self.T\n",
    "\n",
    "        s, l = len(S), len(L)\n",
    "\n",
    "        # initilize the overlap and rbo arrays\n",
    "        # the agreement can be simply calculated from the overlap\n",
    "        X, A, rbo = [0] * l, [0] * l, [0] * l\n",
    "\n",
    "        # first item\n",
    "        S_running, L_running = {S[0]}, {L[0]}  # for O(1) look up\n",
    "        X[0] = 1 if S[0] == L[0] else 0\n",
    "        A[0] = X[0]\n",
    "        rbo[0] = 1.0 * (1 - p) * A[0]\n",
    "\n",
    "        # start the calculation\n",
    "        PP = ProgressPrintOut(l) if self.verbose else NoPrintOut()\n",
    "        disjoint = 0\n",
    "        ext_term = A[0] * p\n",
    "\n",
    "        for d in range(1, l):\n",
    "            PP.printout(d, delta=1)\n",
    "\n",
    "            if d < s:  # still overlapping in length\n",
    "\n",
    "                S_running.add(S[d])\n",
    "                L_running.add(L[d])\n",
    "\n",
    "                # again I will revoke the DP-like step\n",
    "                overlap_incr = 0  # overlap increament at step d\n",
    "\n",
    "                # if the new itmes are the same\n",
    "                if S[d] == L[d]:\n",
    "                    overlap_incr += 1\n",
    "                else:\n",
    "                    # if the new item from S is in L already\n",
    "                    if S[d] in L_running:\n",
    "                        overlap_incr += 1\n",
    "                    # if the new item from L is in S already\n",
    "                    if L[d] in S_running:\n",
    "                        overlap_incr += 1\n",
    "\n",
    "                X[d] = X[d - 1] + overlap_incr\n",
    "                # Eq. (28) that handles the tie. len() is O(1)\n",
    "                A[d] = 2.0 * X[d] / (len(S_running) + len(L_running))\n",
    "                rbo[d] = rbo[d - 1] + 1.0 * (1 - p) * (p**d) * A[d]\n",
    "\n",
    "                ext_term = 1.0 * A[d] * p**(d + 1)  # the extropulate term\n",
    "\n",
    "            else:  # the short list has fallen off the cliff\n",
    "                L_running.add(L[d])  # we still have the long list\n",
    "\n",
    "                # now there is one case\n",
    "                overlap_incr = 1 if L[d] in S_running else 0\n",
    "\n",
    "                X[d] = X[d - 1] + overlap_incr\n",
    "                A[d] = 1.0 * X[d] / (d + 1)\n",
    "                rbo[d] = rbo[d - 1] + 1.0 * (1 - p) * (p**d) * A[d]\n",
    "\n",
    "                X_s = X[s - 1]  # this the last common overlap\n",
    "                # second term in first parenthesis of Eq. (32)\n",
    "                disjoint += 1.0 * (1 - p) * (p**d) * \\\n",
    "                    (X_s * (d + 1 - s) / (d + 1) / s)\n",
    "                ext_term = 1.0 * ((X[d] - X_s) / (d + 1) + X[s - 1] / s) * \\\n",
    "                    p**(d + 1)  # last term in Eq. (32)\n",
    "\n",
    "        return self._bound_range(rbo[-1] + disjoint + ext_term)\n",
    "\n",
    "    def top_weightness(self, p=None, d=None):\n",
    "        \"\"\"\n",
    "        This function will evaluate the degree of the top-weightness of the rbo.\n",
    "        It is the implementation of Eq. (21) of the rbo paper.\n",
    "        As a sanity check (per the rbo paper),\n",
    "        top_weightness(p=0.9, d=10) should be 86%\n",
    "        top_weightness(p=0.98, d=50) should be 86% too\n",
    "        Args:\n",
    "            p (float), defalut None: A value between zero and one.\n",
    "            d (int), default None: Evaluation depth of the list.\n",
    "        Returns:\n",
    "            A float between [0, 1], that indicates the top-weightness.\n",
    "        \"\"\"\n",
    "\n",
    "        # sanity check\n",
    "        if p is None:\n",
    "            p = self.p\n",
    "        assert (0. < p < 1.0)\n",
    "\n",
    "        if d is None:\n",
    "            d = min(self.N_S, self.N_T)\n",
    "        else:\n",
    "            d = min(self.N_S, self.N_T, int(d))\n",
    "\n",
    "        if d == 0:\n",
    "            top_w = 1\n",
    "        elif d == 1:\n",
    "            top_w = 1 - 1 + 1.0 * (1 - p) / p * (np.log(1.0 / (1 - p)))\n",
    "        else:\n",
    "            sum_1 = 0\n",
    "            for i in range(1, d):\n",
    "                sum_1 += 1.0 * p**(i) / i\n",
    "            top_w = 1 - p**(i) + 1.0 * (1 - p) / p * (i + 1) * \\\n",
    "                (np.log(1.0 / (1 - p)) - sum_1)  # here i == d-1\n",
    "\n",
    "        if self.verbose:\n",
    "            print('The first {} ranks have {:6.3%} of the weight of '\n",
    "                  'the evaluation.'.format(d, top_w))\n",
    "\n",
    "        return self._bound_range(top_w)\n",
    "\n",
    "\n",
    "class ProgressPrintOut(object):\n",
    "    \"\"\"Quick status print out.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N):\n",
    "        self._old = 0\n",
    "        self._total = N\n",
    "\n",
    "    def printout(self, i, delta=10):\n",
    "        # print out progess every delta %\n",
    "        cur = 100 * i // self._total\n",
    "        if cur >= self._old + delta:\n",
    "            print('\\r', 'Current progress: {} %...'.format(cur), end='')\n",
    "            self._old = cur\n",
    "        if i == self._total - 1:\n",
    "            print('\\r', 'Current progress: 100 %...', end='')\n",
    "            print('\\nFinished!')\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class NoPrintOut(object):\n",
    "    def printout(self, i, delta=10):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:48:16.182579Z",
     "start_time": "2019-12-09T22:48:16.176225Z"
    }
   },
   "outputs": [],
   "source": [
    "# S = ['ab', 'b', 'd']\n",
    "# T = ['a', 'b', 'dc']\n",
    "# RankingSimilarity(S, T).rbo_ext(p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:48:26.223032Z",
     "start_time": "2019-12-09T22:48:19.936777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import shapSD as ssd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Display all content in dataframe\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T20:46:03.772845Z",
     "start_time": "2019-11-26T20:45:12.209736Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../data/adult.csv'\n",
    "original_adult = pd.read_csv(file_path, index_col=0)\n",
    "df_adult = ssd.DataEncoder(original_adult.drop('income', axis=1)).label_encoding()\n",
    "df_adult = ssd.FeatureProcessing(df_adult).data_scaling()\n",
    "x, y = df_adult.drop(['education'],axis = 1 ), original_adult['income']\n",
    "x_adult_train, x_adult_test, y_adult_train, y_adult_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_test_origin = original_adult.drop('income', axis=1).iloc[x_adult_test.index]\n",
    "y_adult_train = pd.get_dummies(y_adult_train, drop_first=True)\n",
    "y_adult_test = pd.get_dummies(y_adult_test, drop_first=True)\n",
    "\n",
    "nn_model = ssd.InitializeModel(x_adult_train, y_adult_train).keras_nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T20:46:03.779239Z",
     "start_time": "2019-11-26T20:46:03.776280Z"
    }
   },
   "outputs": [],
   "source": [
    "# def subgroup_discovery(df_effect, target_name, label_name, selected_attr, measure, inverse_effect=False,\n",
    "#                            statistic_is_positive=True):\n",
    "#     target = ssd.NumericTarget(target_name)\n",
    "#     search_space = ssd.create_selectors(df_effect, nbins=10, ignore=[target_name, label_name, selected_attr])\n",
    "#     task = ssd.SubgroupDiscoveryTask(df_effect, target, search_space, qf=measure, result_set_size=20, depth=3)\n",
    "#     result = ssd.BeamSearch().execute(task, inverse_effect, statistic_is_positive)\n",
    "#     df_result = ssd.as_df(df_effect, result, statistics_to_show=ssd.all_statistics_numeric)\n",
    "#     return df_result[['quality', 'subgroup', 'size_sg', 'mean_sg', 'mean_dataset', 'mean_lift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T20:46:03.794928Z",
     "start_time": "2019-11-26T20:46:03.782276Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_rank_biased_overlap(attr):\n",
    "    local_exp = ssd.LocalExplainer(x_adult_test, nn_model)\n",
    "    pattern_exp = ssd.PatternExplainer(x_test_origin, x_adult_test, attribute=attr, model=nn_model, \n",
    "                              local_exp=local_exp)\n",
    "    df_lime = pd.read_csv('../data/adult_lime_weights_nn_model.csv', sep='\\t')\n",
    "    df_lime_effect = x_test_origin.copy()\n",
    "    df_lime_effect.reset_index(drop=True, inplace=True)\n",
    "    lime_target_name = '{}_lime_weight'.format(attr)\n",
    "    df_lime_effect[lime_target_name] = df_lime[attr]\n",
    "    pattern_exp.effect_name = lime_target_name\n",
    "    df_lime_result = pattern_exp.subgroup_discovery(df_lime_effect, result_set_size=20)\n",
    "    lime_subgroups = list(df_lime_result['subgroup'].values)\n",
    "    \n",
    "    df_shap = pd.read_csv('../data/adult_shap_value_nn_model.csv', sep='\\t')\n",
    "    df_shap_effect = x_test_origin.copy()\n",
    "    df_shap_effect.reset_index(drop=True, inplace=True)\n",
    "    shap_target_name = '{}_shap_values'.format(attr)\n",
    "    df_shap_effect[shap_target_name] = df_shap[attr]\n",
    "    pattern_exp.effect_name = shap_target_name\n",
    "    df_shap_result = pattern_exp.subgroup_discovery(df_shap_effect, result_set_size=20)\n",
    "    shap_subgroups = list(df_shap_result['subgroup'].values)\n",
    "    \n",
    "    r_similarity = RankingSimilarity(lime_subgroups, shap_subgroups)\n",
    "    # p=0.8, top5 are given 86% weight; p=0.9, top10 are given 85% weight; p=0.95, top30 are given 85% weight\n",
    "    scores = [r_similarity.rbo_ext(p=0.8), r_similarity.rbo_ext(p=0.9), r_similarity.rbo_ext(p=0.95)]\n",
    "    print('attribute: ', attr, 'scores: ', scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T21:15:46.456805Z",
     "start_time": "2019-11-26T20:46:03.797462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute:  age scores:  [0.8529479261463331, 0.8180181917197191, 0.7921633747300507]\n",
      "attribute:  work-class scores:  [0.0, 0.0, 0.0]\n",
      "attribute:  fnlwgt scores:  [0.0, 0.0, 0.0]\n",
      "attribute:  education-num scores:  [0.9245638628841623, 0.8557346789181646, 0.7928860785497591]\n",
      "attribute:  marital-status scores:  [0.7664761043804399, 0.6628783398521207, 0.6188392782579595]\n",
      "attribute:  occupation scores:  [0.12246292753272357, 0.11256213646808358, 0.09124976115876395]\n",
      "attribute:  relationship scores:  [0.32492585506544713, 0.27012427293616714, 0.20624952231752788]\n",
      "attribute:  race scores:  [0.0, 0.0, 0.0]\n",
      "attribute:  sex scores:  [0.9462200758002189, 0.9073873426027799, 0.8680043601804008]\n",
      "attribute:  capital-gain scores:  [0.0, 0.0, 0.0]\n",
      "attribute:  capital-loss scores:  [0.0, 0.0, 0.0]\n",
      "attribute:  hours-per-week scores:  [0.05535666203320279, 0.07580787691559551, 0.08656533333251937]\n",
      "attribute:  native-country scores:  [0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rbo_scores = {}\n",
    "for attr in x_adult_test.columns:\n",
    "    rbo_scores[attr] = calc_rank_biased_overlap(attr=attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T21:15:46.476678Z",
     "start_time": "2019-11-26T21:15:46.459777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p=0.8</th>\n",
       "      <th>p=0.9</th>\n",
       "      <th>p=0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.852948</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>0.792163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work-class</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.924564</td>\n",
       "      <td>0.855735</td>\n",
       "      <td>0.792886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.766476</td>\n",
       "      <td>0.662878</td>\n",
       "      <td>0.618839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.122463</td>\n",
       "      <td>0.112562</td>\n",
       "      <td>0.091250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.324926</td>\n",
       "      <td>0.270124</td>\n",
       "      <td>0.206250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.946220</td>\n",
       "      <td>0.907387</td>\n",
       "      <td>0.868004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.055357</td>\n",
       "      <td>0.075808</td>\n",
       "      <td>0.086565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   p=0.8     p=0.9    p=0.95\n",
       "age             0.852948  0.818018  0.792163\n",
       "work-class      0.000000  0.000000  0.000000\n",
       "fnlwgt          0.000000  0.000000  0.000000\n",
       "education-num   0.924564  0.855735  0.792886\n",
       "marital-status  0.766476  0.662878  0.618839\n",
       "occupation      0.122463  0.112562  0.091250\n",
       "relationship    0.324926  0.270124  0.206250\n",
       "race            0.000000  0.000000  0.000000\n",
       "sex             0.946220  0.907387  0.868004\n",
       "capital-gain    0.000000  0.000000  0.000000\n",
       "capital-loss    0.000000  0.000000  0.000000\n",
       "hours-per-week  0.055357  0.075808  0.086565\n",
       "native-country  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rbo = pd.DataFrame(rbo_scores).transpose()\n",
    "df_rbo.columns = ['p=0.8', 'p=0.9', 'p=0.95']\n",
    "df_rbo"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
